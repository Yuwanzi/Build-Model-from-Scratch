{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K Nearest Neighbor (KNN)** is a popular non-parametric method. The prediction (regression/classification) is obtained by looing into the K cloest memorized examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The algorithm itself can be summarized into three steps:\n",
    "\n",
    "- Select a positive integer K along with a new example\n",
    "\n",
    "- Select K entries in the training databse which are closest to the new example\n",
    "\n",
    "- For regression problem, we perform an average or weighted average of the response of these closest training examples to make the prediction. For classification scenarios, we do a majority vote within the traning entries to assign the label to the new example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class KNearestNeighbors() implements this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class KNearestNeighbors():\n",
    "\n",
    "    def __init__(self, k, model_type='regression', weights='uniform'):\n",
    "\n",
    "        # model_type can be either 'classification' or 'regression'\n",
    "        # weights = 'uniform', the K nearest neighbors are equally weighted\n",
    "        # weights = 'distance', the K nearest entries are weighted by inverse of the distance\n",
    "        self.model_type = model_type\n",
    "        self.k = k\n",
    "        self.weights = weights\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def _dist(self, example1, example2):\n",
    "\n",
    "        # calculate euclidean distance between two examples\n",
    "        if len(example1) != len(example2):\n",
    "            print \"Inconsistent Dimension\"\n",
    "            return\n",
    "\n",
    "        return np.sqrt(sum(np.power(np.array(example1) - np.array(example2), 2)))\n",
    "\n",
    "    def _find_neighbors(self, test_instance):\n",
    "\n",
    "        # find K nearest neighbors for a test instance\n",
    "        # this function return a list of K nearest neighbors for this test instance,\n",
    "        # each element of the list is another list of distance and target\n",
    "        m, n = self.X_train.shape\n",
    "        neighbors = [[self._dist(self.X_train[i, :], test_instance), self.y_train[i]]\n",
    "                     for i in range(m)]\n",
    "        neighbors.sort(key=lambda x: x[0])\n",
    "        return neighbors[:self.k]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # no parameters learning in model fitting process for KNN\n",
    "        # just to store all the training instances\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # predict using KNN algorithm\n",
    "        X = np.array(X)\n",
    "\n",
    "        # if only have one test example to predict\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "\n",
    "        m = X.shape[0]\n",
    "        y_predict = np.zeros((m, 1)).astype(int)\n",
    "\n",
    "        # for regression problems, depending on the weights ('uniform' or 'distance'),\n",
    "        # it will perform average or weighted average based on inverse of distance\n",
    "        if self.model_type == 'regression':\n",
    "            for i in range(m):\n",
    "                distance_mat = np.array(self._find_neighbors(X[i, :]))\n",
    "                if self.weights == 'distance':\n",
    "                    y_predict[i] = np.average(distance_mat[:, 1], weights=1.0/distance_mat[:, 0])\n",
    "                else:\n",
    "                    y_predict[i] = np.average(distance_mat[:, 1])\n",
    "\n",
    "        # for classification, we will apply majority vote for prediction\n",
    "        # it still offer two options in terms of the weights\n",
    "        else:\n",
    "            votes = {}\n",
    "            for i in range(m):\n",
    "                distance_mat = np.array(self._find_neighbors(X[i, :]))\n",
    "                for j in range(self.k):\n",
    "                    if self.weights == 'distance':\n",
    "                        votes[distance_mat[j, 1]] = votes.get(distance_mat[j, 1], 0) + 1.0 / distance_mat[j, 0]\n",
    "                    else:\n",
    "                        votes[distance_mat[j, 1]] = votes.get(distance_mat[j, 1], 0) + 1.0\n",
    "                sorted_votes = sorted(votes.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "                y_predict[i] = sorted_votes[0][0]\n",
    "\n",
    "        return y_predict.ravel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
