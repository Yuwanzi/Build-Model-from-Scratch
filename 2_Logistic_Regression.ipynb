{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150L, 4L)\n",
      "(150L,)\n",
      "Number of Classes: 3\n",
      "True Values:      [0 2 1 2 1 1 1 2 1 0 2 1 2 2 0 2 1 1 2 1 0 2 0 1 2 0 2 2 2 2]\n",
      "Predicted Values: [0 2 1 2 1 1 1 2 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2]\n",
      "Prediction Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "class BinaryLogisticRegression():\n",
    "\n",
    "    def __init__(self, lamda):\n",
    "\n",
    "        self._lamda = lamda\n",
    "\n",
    "    # Define class variables\n",
    "    _mu = None\n",
    "    _sigma = None\n",
    "    _coef = None\n",
    "\n",
    "    def _feature_norm(self, X):\n",
    "\n",
    "        # Normalize all features to expedite the gradient descent process\n",
    "        mu = np.mean(X, axis=0)\n",
    "        sigma = np.std(X, axis=0)\n",
    "        X_norm = (X - mu) / sigma\n",
    "\n",
    "        return X_norm, mu, sigma\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "\n",
    "        # Formulate sigmoid function\n",
    "        return 1.0 / (1.0 + np.exp(-1.0 * z))\n",
    "\n",
    "    def _cost_calc(self, theta, X, y):\n",
    "\n",
    "        # Formulate cost function\n",
    "        m, n = X.shape\n",
    "        y = y.reshape((m, 1))\n",
    "        theta = theta.reshape((n, 1))\n",
    "        z = X.dot(theta)\n",
    "        h_x = self._sigmoid(z)\n",
    "        J = -1.0 / m * (y.T.dot(np.log(h_x)) + (1 - y).T.dot(np.log(1 - h_x))) \\\n",
    "            + self._lamda / (2.0 * m) * sum(theta[1:]**2)\n",
    "\n",
    "        return J.ravel()\n",
    "\n",
    "    def _gradient_calc(self, theta, X, y):\n",
    "\n",
    "        # Formulate the gradient of the cost function\n",
    "        m, n = X.shape\n",
    "        y = y.reshape((m, 1))\n",
    "        theta = theta.reshape((n, 1))\n",
    "        z = X.dot(theta)\n",
    "        h_x = self._sigmoid(z)\n",
    "        grad = np.zeros((n, 1))\n",
    "        grad[0] = 1.0 / m * sum(h_x - y)\n",
    "        grad[1:] = 1.0 / m * X[:, 1:].T.dot(h_x - y) + float(self._lamda) / m * theta[1:]\n",
    "\n",
    "        return grad.ravel()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Fit the model\n",
    "        m, n = X.shape\n",
    "        X, self._mu, self._sigma = self._feature_norm(X)\n",
    "        X = np.c_[np.ones((m, 1)), X]\n",
    "        theta = np.zeros(X.shape[1])\n",
    "        result = scipy.optimize.minimize(fun=self._cost_calc, x0=theta, args=(X, y),\n",
    "                                         method='BFGS', jac=self._gradient_calc,\n",
    "                                         options={\"maxiter\": 100, \"disp\": False})\n",
    "\n",
    "        self._coef = result.x\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "\n",
    "        # predict probabilities with the fitted model\n",
    "        m, n = X.shape\n",
    "        X = np.c_[np.ones((m, 1)), (X - self._mu) / self._sigma]\n",
    "        y_prob = self._sigmoid(X.dot(self._coef.reshape((n+1, 1))))\n",
    "\n",
    "        return y_prob.ravel()\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # predict with the fitted model\n",
    "        p = self.predict_prob(X)\n",
    "        y_predict = np.copy(p)\n",
    "        y_predict[p > 0.5] = 1\n",
    "        y_predict[p <= 0.5] = 0\n",
    "\n",
    "        return y_predict.ravel()\n",
    "\n",
    "\n",
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self, lamda):\n",
    "\n",
    "        self._lamda = lamda\n",
    "\n",
    "    # Define class variables\n",
    "    _values = None\n",
    "    _n_samples = None\n",
    "    _n_classes = None\n",
    "    _lr_list = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # fit the model\n",
    "        self._values = np.unique(y)\n",
    "        self._n_samples = X.shape[0]\n",
    "        self._n_classes = len(self._values)\n",
    "        y_copy = np.array(y)\n",
    "\n",
    "        for value in self._values:\n",
    "            idx = (y == value)\n",
    "            y_copy[idx] = 1\n",
    "            y_copy[~idx] = 0\n",
    "            lr = BinaryLogisticRegression(lamda=self._lamda)\n",
    "            self._lr_list.append(lr.fit(X, y_copy))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "\n",
    "        # predict the probabilities for each class\n",
    "        y_prob_ini = np.empty((X.shape[0], self._n_classes))\n",
    "        for k, lr in enumerate(self._lr_list):\n",
    "            y_prob_ini[:, k] = lr.predict_prob(X)\n",
    "\n",
    "        row_sums = y_prob_ini.sum(axis=1)\n",
    "        y_prob = y_prob_ini / row_sums[:, np.newaxis]\n",
    "        return y_prob\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # predict with one_versus_all scheme\n",
    "        p = self.predict_prob(X)\n",
    "        y_predict_idx = np.argmax(p, axis=1)\n",
    "        y_predict = np.array([self._values[i] for i in y_predict_idx])\n",
    "        return y_predict\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "print X.shape\n",
    "print y.shape\n",
    "print \"Number of Classes: {}\".format(len(np.unique(y)))\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "lr = LogisticRegression(lamda=1)\n",
    "lr = lr.fit(X_train, y_train)\n",
    "y_predict = lr.predict(X_test)\n",
    "\n",
    "print \"True Values:      {}\".format(y_test)\n",
    "print \"Predicted Values: {}\".format(y_predict)\n",
    "print \"Prediction Accuracy: {:.2%}\".format(np.mean((y_predict == y_test).astype(float)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
